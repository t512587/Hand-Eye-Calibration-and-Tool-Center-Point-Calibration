import cv2
import numpy as np
import pyrealsense2 as rs
from ultralytics import YOLO
from pymycobot.elephantrobot import ElephantRobot, JogMode
from scipy.spatial.transform import Rotation as R
import time

# --- åŸºç¤å·¥å…·å‡½æ•¸ ---
def transform_point(T, P):
    """ ä½¿ç”¨ 4x4 çŸ©é™£è½‰æ› 3D é» """
    P_h = np.ones(4)
    P_h[:3] = P
    P_transformed = T @ P_h
    return P_transformed[:3]

class StoneGrabSystem:
    def __init__(self):
        # 1. åƒæ•¸è¨­å®š
        self.model_path = "best.pt"
        self.robot_ip = "192.168.50.123"
        self.robot_port = 5001
        self.conf_threshold = 0.9
        self.move_speed = 1000        
        self.arrival_timeout = 30    
        self.home_angles = [-10, -85, 90, -95, -90, -40]

        print("=" * 60)
        print(f"ğŸš€ å•Ÿå‹•ç³»çµ±... é€Ÿåº¦: {self.move_speed} | ä¿¡å¿ƒåº¦: {self.conf_threshold}")
        
        # 2. åˆå§‹åŒ– RealSense
        try:
            self.pipeline = rs.pipeline()
            config = rs.config()
            config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
            config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
            self.profile = self.pipeline.start(config)
            self.align = rs.align(rs.stream.color)
            self.intrinsics = self.profile.get_stream(rs.stream.color).as_video_stream_profile().get_intrinsics()
            print("âœ“ RealSense ç›¸æ©Ÿåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ ç›¸æ©Ÿå•Ÿå‹•å¤±æ•—: {e}")

        # 3. è¼‰å…¥æ¨¡å‹èˆ‡æ¨™å®šçŸ©é™£
        self.model = YOLO(self.model_path)
        self.T_camera_gripper = np.array([
            [-0.92763612,  0.37336914, -0.0093117,   0.01855558],
            [-0.37346284, -0.92701915,  0.03407355,  0.03314082],
            [ 0.00408989,  0.03508543,  0.99937595,  0.04703275],
            [ 0.00000000,  0.00000000,  0.00000000,  1.00000000]
        ])
        self.tcp_offset = np.array([0, 0, -120]) / 1000.0 

        # 4. é€£æ¥æ©Ÿæ¢°æ‰‹è‡‚
        try:
            self.robot = ElephantRobot(self.robot_ip, self.robot_port)
            self.robot.start_client()
            time.sleep(1) # çµ¦äºˆé€£ç·šç·©è¡
            print("âœ“ æ©Ÿæ¢°æ‰‹è‡‚é€£ç·šæˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ‰‹è‡‚é€£ç·šå¤±æ•—: {e}")
            self.robot = None

        self.latest_object = None
        self.running = False

    def wait_arrival(self, target, mode="coords"):
        """ æ”¹è‰¯ç‰ˆç­‰å¾…å‡½æ•¸ï¼Œå¢åŠ ç©©å®šæ€§ """
        start_t = time.time()
        check_mode = JogMode.JOG_TELEOP if mode == "coords" else JogMode.JOG_JOINT
        
        time.sleep(0.3) # æŒ‡ä»¤ç™¼é€å¾Œçš„ç‰©ç†åæ‡‰å»¶é²
        while time.time() - start_t < self.arrival_timeout:
            try:
                if self.robot.is_in_position(target, check_mode):
                    actual = self.robot.get_coords() if mode == "coords" else self.robot.get_angles()
                    print(f"   âœ“ åˆ°é”ç›®æ¨™ä½ç½®")
                    return True
            except:
                pass 
            time.sleep(0.2)
        print(f"   âš ï¸ {mode} ç§»å‹•é€¾æ™‚")
        return False

    def control_gripper(self, open_gr):
        """ å¤¾çˆªæ§åˆ¶ """
        if self.robot:
            state = 0 if open_gr else 1
            self.robot.set_digital_out(16, state)
            self.robot.set_digital_out(17, 1 - state)
            time.sleep(1.0) 

    def get_base_coords(self, pixel_x, pixel_y, depth_frame):
        """ åƒç´ è½‰åŸºåº§åº§æ¨™ """
        depth = depth_frame.get_distance(pixel_x, pixel_y)
        if depth == 0 or self.robot is None: return None
        
        cam_p = rs.rs2_deproject_pixel_to_point(self.intrinsics, [pixel_x, pixel_y], depth)
        curr = self.robot.get_coords()
        if not curr: return None
        
        xyz, rpy = np.array(curr[:3])/1000.0, curr[3:]
        
        T_base_gripper = np.eye(4)
        T_base_gripper[:3, 3] = xyz
        T_base_gripper[:3, :3] = R.from_euler('xyz', rpy, degrees=True).as_matrix()
        
        P_gripper = transform_point(self.T_camera_gripper, cam_p)
        P_base_raw = transform_point(T_base_gripper, P_gripper)
        P_base = P_base_raw - self.tcp_offset 
        
        return P_base * 1000.0

    def grab_process(self):
        """ æ ¸å¿ƒæŠ“å–æµç¨‹ï¼ˆéé˜»å¡ç‰ˆï¼‰ """
        if not self.latest_object:
            print("âš ï¸ æœªé–å®šç›®æ¨™ï¼Œå–æ¶ˆæ“ä½œ")
            return

        target_xyz = self.latest_object['base_pos']
        print(f"\nğŸ“ ç›®æ¨™ç¢ºå®š: X:{target_xyz[0]:.1f} Y:{target_xyz[1]:.1f} Z:{target_xyz[2]:.1f}")
        
        # ç²å–ç•¶å‰å§¿æ…‹ RPY
        curr_coords = self.robot.get_coords()
        if not curr_coords: 
            print("âŒ ç„¡æ³•å–å¾—æ‰‹è‡‚åº§æ¨™")
            return
        curr_rpy = curr_coords[3:]
        
        # å®šç¾©è·¯å¾‘é»
        up_pos = [target_xyz[0], target_xyz[1], target_xyz[2] + 50, *curr_rpy]
        down_pos = [target_xyz[0], target_xyz[1], target_xyz[2] - 5, *curr_rpy]
        
        try:
            print("Step 1: ç§»è‡³ä¸Šæ–¹...")
            self.robot.write_coords(up_pos, self.move_speed)
            if not self.wait_arrival(up_pos): return

            print("Step 2: é–‹çˆª...")
            self.control_gripper(True)

            print("Step 3: ä¸‹é™æŠ“å–...")
            self.robot.write_coords(down_pos, self.move_speed)
            if not self.wait_arrival(down_pos): return

            print("Step 4: å¤¾ç·Š...")
            self.control_gripper(False)

            print("Step 5: æèµ·...")
            lift_pos = [target_xyz[0], target_xyz[1], target_xyz[2] + 100, *curr_rpy]
            self.robot.write_coords(lift_pos, self.move_speed)
            self.wait_arrival(lift_pos)
            self.control_gripper(True)
            print("Step 6: å¾©ä½...")
            self.robot.write_angles(self.home_angles, self.move_speed)
            self.wait_arrival(self.home_angles, mode="angles")
            self.control_gripper(False)
            
            print("âœ¨ ä»»å‹™åœ“æ»¿å®Œæˆ")
        except Exception as e:
            print(f"âŒ åŸ·è¡Œä¸­æ–·: {e}")

    def run(self):
        self.running = True
        print("\n[æ“ä½œæç¤º]")
        print(" > æŒ‰ 'g' éµï¼šåŸ·è¡Œè‡ªå‹•æŠ“å–æµç¨‹")
        print(" > æŒ‰ 'q' éµï¼šçµæŸç¨‹å¼")
        
        try:
            while self.running:
                frames = self.pipeline.wait_for_frames()
                aligned = self.align.process(frames)
                color_img = np.asanyarray(aligned.get_color_frame().get_data())
                depth_frame = aligned.get_depth_frame()

                # æ¨è«–
                results = self.model(color_img, conf=self.conf_threshold, verbose=False)
                
                # è™•ç†åµæ¸¬çµæœ
                if len(results) > 0 and results[0].masks is not None:
                    # æŠ“å–ä¿¡å¿ƒåº¦æœ€é«˜çš„ç‰©ä»¶
                    boxes = results[0].boxes.data.cpu().numpy()
                    idx = np.argmax(boxes[:, 4])
                    
                    mask = results[0].masks.data.cpu().numpy()[idx]
                    mask_res = cv2.resize(mask, (640, 480))
                    y_c, x_c = np.where(mask_res > 0.5)
                    
                    if len(x_c) > 0:
                        cx, cy = int(np.mean(x_c)), int(np.mean(y_c))
                        base_p = self.get_base_coords(cx, cy, depth_frame)
                        
                        if base_p is not None:
                            self.latest_object = {'base_pos': base_p}
                            # è¦–è¦ºè¼”åŠ©
                            cv2.circle(color_img, (cx, cy), 7, (0, 0, 255), -1)
                            cv2.putText(color_img, f"READY: {base_p[0]:.0f}, {base_p[1]:.0f}", 
                                        (cx+15, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

                cv2.imshow('Stone Grabber System', color_img)
                
                # é—œéµï¼šä½¿ç”¨ OpenCV çš„ waitKey ä¾†è™•ç†äº’å‹•
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('g'):
                    if self.latest_object:
                        self.grab_process()
                    else:
                        print("âš ï¸ ç•«é¢ä¸Šæ²’çœ‹åˆ°ç›®æ¨™ç‰©å–”ï¼")

        finally:
            print("\nç³»çµ±é—œé–‰ä¸­...")
            if self.pipeline:
                self.pipeline.stop()
            cv2.destroyAllWindows()

if __name__ == "__main__":
    system = StoneGrabSystem()
    system.run()